{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8193534e-829a-4c24-b72f-8129cd6f98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 05:52:14.476083: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 05:52:14.516522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:14.527756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:14.529073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.409166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.410746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.412019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.413292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 558 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "'/device:GPU:0'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1786ea4-e8ef-4f26-9e83-11b9afd9db1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 05:52:15.635504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.637012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.638294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.639901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.641188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.642489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.643821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.645085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 05:52:15.646314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 558 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "2022-12-06 05:52:15.692682: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.experimental.load(\"./acceptance-train.tfrecords\")\n",
    "validation_dataset = tf.data.experimental.load(\"./acceptance-validation.tfrecords\").batch(1000)\n",
    "\n",
    "X, y = next(iter(train_dataset.batch(100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#model_type = 'pure_sequential'\n",
    "model_type = 'with_residual_layers'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c192b02-e513-47fb-98a3-8d1d955fece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'pure_sequential':\n",
    "    layers = []\n",
    "    layers += [tf.keras.layers.Dense(128, activation='tanh', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.L2(1e-3)) for _ in range(4)]\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.build(input_shape = [None, X.shape[1]])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          1408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128)          0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128)          0           add[0][0]                        \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          16512       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128)          0           add_1[0][0]                      \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          16512       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128)          0           add_2[0][0]                      \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128)          0           add_3[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          16512       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128)          0           add_4[0][0]                      \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          16512       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 128)          0           add_5[0][0]                      \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          16512       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 128)          0           add_6[0][0]                      \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          16512       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 128)          0           add_7[0][0]                      \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          16512       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 128)          0           add_8[0][0]                      \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            129         add_9[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 166,657\n",
      "Trainable params: 166,657\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if model_type == 'with_residual_layers':\n",
    "    input = tf.keras.layers.Input(batch_input_shape=[None]+X.shape[1:])\n",
    "    x = tf.keras.layers.Dense(\n",
    "        128, activation='tanh',\n",
    "        kernel_initializer='he_normal',\n",
    "        kernel_regularizer=tf.keras.regularizers.L2(1e-3)\n",
    "    )(input)\n",
    "\n",
    "    for i in range(10):\n",
    "        r = tf.keras.layers.Dense(128, activation='tanh', kernel_initializer='zeros')(x)\n",
    "        x = tf.keras.layers.Add()([x, r])\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input], outputs=[x])\n",
    "    model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca8c457b-076b-4340-996f-695ae7598c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "134972ba-596f-45fc-a754-22ab990fcf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 05:52:30.367725: W tensorflow/core/common_runtime/bfc_allocator.cc:457] Allocator (GPU_0_bfc) ran out of memory trying to allocate 48.83MiB (rounded to 51200000)requested by op model/dense_6/MatMul\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-12-06 05:52:30.367815: I tensorflow/core/common_runtime/bfc_allocator.cc:1004] BFCAllocator dump for GPU_0_bfc\n",
      "2022-12-06 05:52:30.367830: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (256): \tTotal Chunks: 33, Chunks in use: 32. 8.2KiB allocated for chunks. 8.0KiB in use in bin. 157B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367836: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (512): \tTotal Chunks: 36, Chunks in use: 36. 18.2KiB allocated for chunks. 18.2KiB in use in bin. 18.0KiB client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367841: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367846: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367850: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (4096): \tTotal Chunks: 6, Chunks in use: 5. 29.5KiB allocated for chunks. 25.0KiB in use in bin. 25.0KiB client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367854: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367858: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367862: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367867: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (65536): \tTotal Chunks: 30, Chunks in use: 30. 1.88MiB allocated for chunks. 1.88MiB in use in bin. 1.88MiB client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367871: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367876: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (262144): \tTotal Chunks: 1, Chunks in use: 1. 390.8KiB allocated for chunks. 390.8KiB in use in bin. 390.6KiB client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367880: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367883: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367887: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 1. 3.81MiB allocated for chunks. 3.81MiB in use in bin. 3.81MiB client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367891: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367895: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367899: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367907: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (33554432): \tTotal Chunks: 11, Chunks in use: 11. 551.87MiB allocated for chunks. 551.87MiB in use in bin. 537.11MiB client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367911: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367915: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367935: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-06 05:52:30.367947: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] Bin for 48.83MiB was 32.00MiB, Chunk State: \n",
      "2022-12-06 05:52:30.367952: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Next region of size 585105408\n",
      "2022-12-06 05:52:30.367961: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8000000 of size 1280 next 1\n",
      "2022-12-06 05:52:30.367964: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8000500 of size 256 next 2\n",
      "2022-12-06 05:52:30.367967: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8000600 of size 256 next 3\n",
      "2022-12-06 05:52:30.367971: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8000700 of size 256 next 4\n",
      "2022-12-06 05:52:30.367974: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8000800 of size 256 next 5\n",
      "2022-12-06 05:52:30.367977: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8000900 of size 256 next 6\n",
      "2022-12-06 05:52:30.367980: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8000a00 of size 256 next 7\n",
      "2022-12-06 05:52:30.367983: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8000b00 of size 512 next 10\n",
      "2022-12-06 05:52:30.367987: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8000d00 of size 512 next 12\n",
      "2022-12-06 05:52:30.367990: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8000f00 of size 512 next 14\n",
      "2022-12-06 05:52:30.367993: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8001100 of size 512 next 16\n",
      "2022-12-06 05:52:30.367996: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8001300 of size 512 next 18\n",
      "2022-12-06 05:52:30.368000: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8001500 of size 512 next 20\n",
      "2022-12-06 05:52:30.368003: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8001700 of size 512 next 22\n",
      "2022-12-06 05:52:30.368006: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8001900 of size 512 next 24\n",
      "2022-12-06 05:52:30.368009: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8001b00 of size 512 next 26\n",
      "2022-12-06 05:52:30.368012: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8001d00 of size 512 next 28\n",
      "2022-12-06 05:52:30.368015: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8001f00 of size 512 next 30\n",
      "2022-12-06 05:52:30.368018: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002100 of size 256 next 31\n",
      "2022-12-06 05:52:30.368021: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002200 of size 256 next 32\n",
      "2022-12-06 05:52:30.368025: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002300 of size 256 next 35\n",
      "2022-12-06 05:52:30.368028: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002400 of size 256 next 36\n",
      "2022-12-06 05:52:30.368032: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002500 of size 256 next 33\n",
      "2022-12-06 05:52:30.368035: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002600 of size 512 next 34\n",
      "2022-12-06 05:52:30.368038: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002800 of size 256 next 37\n",
      "2022-12-06 05:52:30.368042: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002900 of size 256 next 38\n",
      "2022-12-06 05:52:30.368045: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002a00 of size 256 next 39\n",
      "2022-12-06 05:52:30.368048: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002b00 of size 256 next 40\n",
      "2022-12-06 05:52:30.368051: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002c00 of size 256 next 41\n",
      "2022-12-06 05:52:30.368054: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002d00 of size 256 next 42\n",
      "2022-12-06 05:52:30.368057: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002e00 of size 256 next 43\n",
      "2022-12-06 05:52:30.368061: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8002f00 of size 768 next 8\n",
      "2022-12-06 05:52:30.368064: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8003200 of size 5120 next 9\n",
      "2022-12-06 05:52:30.368067: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8004600 of size 65536 next 11\n",
      "2022-12-06 05:52:30.368070: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8014600 of size 65536 next 13\n",
      "2022-12-06 05:52:30.368074: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8024600 of size 65536 next 15\n",
      "2022-12-06 05:52:30.368077: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8034600 of size 65536 next 17\n",
      "2022-12-06 05:52:30.368080: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8044600 of size 65536 next 19\n",
      "2022-12-06 05:52:30.368083: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8054600 of size 65536 next 21\n",
      "2022-12-06 05:52:30.368086: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8064600 of size 65536 next 23\n",
      "2022-12-06 05:52:30.368089: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8074600 of size 65536 next 25\n",
      "2022-12-06 05:52:30.368092: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8084600 of size 65536 next 27\n",
      "2022-12-06 05:52:30.368095: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8094600 of size 65536 next 29\n",
      "2022-12-06 05:52:30.368099: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80a4600 of size 5120 next 44\n",
      "2022-12-06 05:52:30.368102: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80a5a00 of size 65536 next 45\n",
      "2022-12-06 05:52:30.368105: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80b5a00 of size 512 next 46\n",
      "2022-12-06 05:52:30.368108: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80b5c00 of size 65536 next 47\n",
      "2022-12-06 05:52:30.368112: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80c5c00 of size 512 next 48\n",
      "2022-12-06 05:52:30.368115: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80c5e00 of size 65536 next 49\n",
      "2022-12-06 05:52:30.368118: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80d5e00 of size 512 next 50\n",
      "2022-12-06 05:52:30.368121: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80d6000 of size 65536 next 51\n",
      "2022-12-06 05:52:30.368124: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80e6000 of size 512 next 52\n",
      "2022-12-06 05:52:30.368127: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80e6200 of size 65536 next 53\n",
      "2022-12-06 05:52:30.368130: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80f6200 of size 512 next 54\n",
      "2022-12-06 05:52:30.368135: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca80f6400 of size 65536 next 55\n",
      "2022-12-06 05:52:30.368138: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8106400 of size 512 next 56\n",
      "2022-12-06 05:52:30.368141: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8106600 of size 65536 next 57\n",
      "2022-12-06 05:52:30.368144: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8116600 of size 512 next 58\n",
      "2022-12-06 05:52:30.368147: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8116800 of size 65536 next 59\n",
      "2022-12-06 05:52:30.368150: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8126800 of size 512 next 60\n",
      "2022-12-06 05:52:30.368154: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8126a00 of size 65536 next 61\n",
      "2022-12-06 05:52:30.368157: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8136a00 of size 512 next 62\n",
      "2022-12-06 05:52:30.368160: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8136c00 of size 65536 next 63\n",
      "2022-12-06 05:52:30.368163: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8146c00 of size 512 next 64\n",
      "2022-12-06 05:52:30.368166: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8146e00 of size 512 next 65\n",
      "2022-12-06 05:52:30.368169: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8147000 of size 256 next 66\n",
      "2022-12-06 05:52:30.368172: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8147100 of size 256 next 67\n",
      "2022-12-06 05:52:30.368176: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8147200 of size 5120 next 68\n",
      "2022-12-06 05:52:30.368179: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8148600 of size 256 next 69\n",
      "2022-12-06 05:52:30.368182: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8148700 of size 256 next 70\n",
      "2022-12-06 05:52:30.368185: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8148800 of size 256 next 71\n",
      "2022-12-06 05:52:30.368188: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8148900 of size 256 next 72\n",
      "2022-12-06 05:52:30.368192: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8148a00 of size 256 next 73\n",
      "2022-12-06 05:52:30.368195: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8148b00 of size 256 next 74\n",
      "2022-12-06 05:52:30.368198: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8148c00 of size 256 next 75\n",
      "2022-12-06 05:52:30.368201: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 7fcca8148d00 of size 256 next 107\n",
      "2022-12-06 05:52:30.368204: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8148e00 of size 256 next 109\n",
      "2022-12-06 05:52:30.368208: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 7fcca8148f00 of size 4608 next 76\n",
      "2022-12-06 05:52:30.368211: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca814a100 of size 5120 next 77\n",
      "2022-12-06 05:52:30.368214: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca814b500 of size 512 next 78\n",
      "2022-12-06 05:52:30.368217: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca814b700 of size 65536 next 79\n",
      "2022-12-06 05:52:30.368220: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca815b700 of size 512 next 80\n",
      "2022-12-06 05:52:30.368223: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca815b900 of size 5120 next 81\n",
      "2022-12-06 05:52:30.368227: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca815cd00 of size 512 next 82\n",
      "2022-12-06 05:52:30.368230: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca815cf00 of size 65536 next 83\n",
      "2022-12-06 05:52:30.368233: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca816cf00 of size 65536 next 84\n",
      "2022-12-06 05:52:30.368237: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca817cf00 of size 512 next 85\n",
      "2022-12-06 05:52:30.368240: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca817d100 of size 65536 next 86\n",
      "2022-12-06 05:52:30.368243: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca818d100 of size 512 next 87\n",
      "2022-12-06 05:52:30.368247: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca818d300 of size 65536 next 88\n",
      "2022-12-06 05:52:30.368250: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca819d300 of size 512 next 89\n",
      "2022-12-06 05:52:30.368253: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca819d500 of size 65536 next 90\n",
      "2022-12-06 05:52:30.368256: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81ad500 of size 512 next 91\n",
      "2022-12-06 05:52:30.368259: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81ad700 of size 65536 next 92\n",
      "2022-12-06 05:52:30.368262: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81bd700 of size 512 next 93\n",
      "2022-12-06 05:52:30.368266: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81bd900 of size 512 next 94\n",
      "2022-12-06 05:52:30.368269: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81bdb00 of size 256 next 95\n",
      "2022-12-06 05:52:30.368272: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81bdc00 of size 65536 next 96\n",
      "2022-12-06 05:52:30.368275: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81cdc00 of size 65536 next 97\n",
      "2022-12-06 05:52:30.368287: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81ddc00 of size 512 next 98\n",
      "2022-12-06 05:52:30.368290: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81dde00 of size 256 next 99\n",
      "2022-12-06 05:52:30.368293: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81ddf00 of size 65536 next 100\n",
      "2022-12-06 05:52:30.368296: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81edf00 of size 512 next 101\n",
      "2022-12-06 05:52:30.368299: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81ee100 of size 512 next 102\n",
      "2022-12-06 05:52:30.368302: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81ee300 of size 256 next 103\n",
      "2022-12-06 05:52:30.368306: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81ee400 of size 256 next 104\n",
      "2022-12-06 05:52:30.368309: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca81ee500 of size 400128 next 105\n",
      "2022-12-06 05:52:30.368313: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8250000 of size 4000000 next 106\n",
      "2022-12-06 05:52:30.368316: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fcca8620900 of size 51200000 next 108\n",
      "2022-12-06 05:52:30.368319: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fccab6f4900 of size 51200000 next 110\n",
      "2022-12-06 05:52:30.368322: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fccae7c8900 of size 51200000 next 111\n",
      "2022-12-06 05:52:30.368325: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fccb189c900 of size 51200000 next 112\n",
      "2022-12-06 05:52:30.368329: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fccb4970900 of size 51200000 next 113\n",
      "2022-12-06 05:52:30.368332: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fccb7a44900 of size 51200000 next 114\n",
      "2022-12-06 05:52:30.368335: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fccbab18900 of size 51200000 next 115\n",
      "2022-12-06 05:52:30.368338: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fccbdbec900 of size 51200000 next 116\n",
      "2022-12-06 05:52:30.368341: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fccc0cc0900 of size 51200000 next 117\n",
      "2022-12-06 05:52:30.368346: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fccc3d94900 of size 51200000 next 118\n",
      "2022-12-06 05:52:30.368349: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fccc6e68900 of size 66680576 next 18446744073709551615\n",
      "2022-12-06 05:52:30.368352: I tensorflow/core/common_runtime/bfc_allocator.cc:1065]      Summary of in-use Chunks by size: \n",
      "2022-12-06 05:52:30.368357: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 32 Chunks of size 256 totalling 8.0KiB\n",
      "2022-12-06 05:52:30.368361: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 35 Chunks of size 512 totalling 17.5KiB\n",
      "2022-12-06 05:52:30.368364: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 768 totalling 768B\n",
      "2022-12-06 05:52:30.368368: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-12-06 05:52:30.368394: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 5 Chunks of size 5120 totalling 25.0KiB\n",
      "2022-12-06 05:52:30.368398: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 30 Chunks of size 65536 totalling 1.88MiB\n",
      "2022-12-06 05:52:30.368402: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 400128 totalling 390.8KiB\n",
      "2022-12-06 05:52:30.368422: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 4000000 totalling 3.81MiB\n",
      "2022-12-06 05:52:30.368426: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 10 Chunks of size 51200000 totalling 488.28MiB\n",
      "2022-12-06 05:52:30.368430: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 66680576 totalling 63.59MiB\n",
      "2022-12-06 05:52:30.368434: I tensorflow/core/common_runtime/bfc_allocator.cc:1072] Sum Total of in-use chunks: 558.00MiB\n",
      "2022-12-06 05:52:30.368438: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] total_region_allocated_bytes_: 585105408 memory_limit_: 585105408 available bytes: 0 curr_region_allocation_bytes_: 1170210816\n",
      "2022-12-06 05:52:30.368447: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] Stats: \n",
      "Limit:                       585105408\n",
      "InUse:                       585100544\n",
      "MaxInUse:                    585100544\n",
      "NumAllocs:                         126\n",
      "MaxAllocSize:                 66680576\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-12-06 05:52:30.368458: W tensorflow/core/common_runtime/bfc_allocator.cc:468] **************************************************************************************************xx\n",
      "2022-12-06 05:52:30.368546: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at matmul_op_impl.h:681 : Resource exhausted: OOM when allocating tensor with shape[100000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[100000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/dense_6/MatMul (defined at tmp/ipykernel_2591/3694947802.py:4) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1997]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m      3\u001B[0m data \u001B[38;5;241m=\u001B[39m train_dataset\u001B[38;5;241m.\u001B[39mbatch(\u001B[38;5;241m100_000\u001B[39m)\u001B[38;5;241m.\u001B[39mprefetch(tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mAUTOTUNE)\n\u001B[0;32m----> 4\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mvalidation_dataset\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/miniconda3/envs/tf_on_gpu/lib/python3.9/site-packages/keras/engine/training.py:1184\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1178\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1179\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1180\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1181\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1182\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1183\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1184\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1185\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1186\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/usr/local/miniconda3/envs/tf_on_gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    882\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 885\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    887\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    888\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/usr/local/miniconda3/envs/tf_on_gpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:950\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    946\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Fall through to cond-based initialization.\u001B[39;00m\n\u001B[1;32m    947\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    948\u001B[0m     \u001B[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001B[39;00m\n\u001B[1;32m    949\u001B[0m     \u001B[38;5;66;03m# stateless function.\u001B[39;00m\n\u001B[0;32m--> 950\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    951\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    952\u001B[0m   _, _, _, filtered_flat_args \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m    953\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn\u001B[38;5;241m.\u001B[39m_function_spec\u001B[38;5;241m.\u001B[39mcanonicalize_function_inputs(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    954\u001B[0m           \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[0;32m/usr/local/miniconda3/envs/tf_on_gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3039\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   3037\u001B[0m   (graph_function,\n\u001B[1;32m   3038\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3040\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/miniconda3/envs/tf_on_gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1963\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1959\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1961\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1962\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1963\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1964\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1965\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1966\u001B[0m     args,\n\u001B[1;32m   1967\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1968\u001B[0m     executing_eagerly)\n\u001B[1;32m   1969\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/usr/local/miniconda3/envs/tf_on_gpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    590\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 591\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    592\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    597\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    598\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    599\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    600\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    603\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    604\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m/usr/local/miniconda3/envs/tf_on_gpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     58\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 59\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     62\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mResourceExhaustedError\u001B[0m:  OOM when allocating tensor with shape[100000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/dense_6/MatMul (defined at tmp/ipykernel_2591/3694947802.py:4) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1997]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=BinaryCrossentropy(label_smoothing=0.01), optimizer=RMSprop(10e-3))\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "data = train_dataset.batch(100_000).prefetch(tf.data.AUTOTUNE)\n",
    "history = model.fit(data, epochs=50, validation_data=next(iter(validation_dataset)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65cec0c-e525-4d8f-a0bc-127f6bd10347",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=BinaryCrossentropy(label_smoothing=0.00), optimizer=RMSprop(1e-3))\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "data = train_dataset.batch(100_000).prefetch(tf.data.AUTOTUNE)\n",
    "history_ft = model.fit(data, epochs=50, validation_data=next(iter(validation_dataset)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5d610-777b-4c14-b3d8-f84b39ae4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'] + history_ft.history['loss'], label=\"Loss (train)\")\n",
    "plt.plot(history.history['val_loss'] + history_ft.history['val_loss'], label=\"Loss (validation)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Binary cross-entropy\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Xv, yv = next(iter(validation_dataset.unbatch().batch(1_000_000).as_numpy_iterator()))\n",
    "yv_hat = model.predict(Xv, batch_size=len(Xv))\n",
    "bins = np.linspace(0, 1, 11)\n",
    "plt.hist(yv, bins=bins, label=\"Training labels\")\n",
    "plt.hist(yv_hat, bins=bins, histtype='step', linewidth=2, label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_p = Xv[:,3]\n",
    "bins = np.linspace(-4, 4, 241)\n",
    "denominator, _ = np.histogram(log_p, bins=bins)\n",
    "true_numerator, _ = np.histogram(log_p, bins=bins, weights=yv.flatten())\n",
    "predicted_numerator, _ = np.histogram(log_p, bins=bins, weights=yv_hat.flatten())\n",
    "\n",
    "plt.plot((bins[1:] + bins[:-1])/2, denominator, label=\"Generated\")\n",
    "plt.plot((bins[1:] + bins[:-1])/2, predicted_numerator, label=\"In acceptance (model)\")\n",
    "plt.fill_between(\n",
    "    (bins[1:] + bins[:-1])/2, np.zeros(len(true_numerator)), true_numerator,\n",
    "    label=\"In acceptance (validation)\"\n",
    ")\n",
    "plt.xlabel(r\"$\\log_{10} \\left(p / (1 \\mathrm{MeV}/c\\right)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0989f48-83a5-4635-8fc9-c2647dfea999",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /workarea/cloud-storage/anderlinil/models\n",
    "model.save(\"/workarea/cloud-storage/anderlinil/models/acceptance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tf_on_gpu",
   "language": "python",
   "display_name": "TensorFlow on GPU"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}